{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4: Model Training\n",
    "First we import the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from pythermondt import transforms as T\n",
    "from pythermondt.data import ThermoDataset, DataContainer, random_split\n",
    "from pythermondt.readers import S3Reader\n",
    "from example_models.defect_classifier import DefectClassifier3DCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define some general parameters for the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 1\n",
    "batch_size = 2\n",
    "learning_rate = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can the define all the datasources used for training. Here you could specifiy multiple datasources (which are later combined usign the dataset) if you need that. In this example we only use one datasource.\n",
    "\n",
    "**Note:** For the S3Reader object we set the cache_files flag to true. Therefore all the files are cached to a folder (.pyThermoNDT_cache) in the current working directory. This makes training way faster, because the files are now only downloaded once and not every time the datasource is loaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b96b487e0a1a4ea09da0dde55b21b288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading Files for S3Reader(source=s3://ffg-bp/example4_model_training/.hdf5):   0%|          | 0/195 [00:0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Specifiy the datasource\n",
    "s3reader = S3Reader(\n",
    "    source='s3://ffg-bp/example4_model_training/.hdf5',\n",
    "    cache_files=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can combine these datasources by creating a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dataset\n",
    "dataset = ThermoDataset(data_source=s3reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards the transform pipeline which will be applied to the data before it gets fed into the model is defined. In this example we use Data Augmentation techniques like flipping and rotating the images or adding noise to the images (to simulate NETD of the camera). Therefore we need 2 different pipelines. One for the training set and one for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup transform pipeline for training set\n",
    "train_pipeline = T.Compose([\n",
    "    T.ApplyLUT(),\n",
    "    T.GaussianNoise(std=1e-3), # Data Augmentation\n",
    "    T.RandomFlip(p_height=0.3, p_width=0.3), # Data Augmentation\n",
    "    T.SubstractFrame(0), \n",
    "    T.RemoveFlash(method='excitation_signal'),\n",
    "    T.NonUniformSampling(64),\n",
    "    T.MinMaxNormalize(),\n",
    "])\n",
    "\n",
    "# Setup transform pipeline for test set\n",
    "test_pipeline = T.Compose([\n",
    "    T.ApplyLUT(),\n",
    "    T.SubstractFrame(0), \n",
    "    T.RemoveFlash(method='excitation_signal'),\n",
    "    T.NonUniformSampling(64),\n",
    "    T.MinMaxNormalize(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can continue, we first need to write a custom collate function. All our readers and datasets always load data in form of Datacontainer objects. However, when training a model the input data needs to be in form of a tensor. Therefore the collate function extracts the data from all the Datacontainer objects in the current batch and stacks them along the batch dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom collate function to extract data and target from the DataContainers in the batch\n",
    "def collate_fn(batch: list[DataContainer]) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    # Extract data and target from the DataContainers\n",
    "    tdata = []\n",
    "    mask = []\n",
    "\n",
    "    # Extract the data and label from the DataContainer\n",
    "    for container in batch:\n",
    "        tdata.append(container.get_dataset(\"/Data/Tdata\").unsqueeze(0)[:,:,0:499])\n",
    "        mask.append(torch.tensor([0, 1]) if container.get_dataset(\"/GroundTruth/DefectMask\").equal(torch.zeros(100,100)) else torch.tensor([1, 0]))\n",
    "\n",
    "    # Stack the tensors along the batch dimension\n",
    "    data = torch.stack(tdata).to(device=device, dtype=torch.float32)\n",
    "    label = torch.stack(mask).to(device=device, dtype=torch.float32)\n",
    "\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can split the dataset into a training and validation subset, using the random_split function provided with pyThermoNDT. Afterwards the dataloaders for each of the subsets are created.\n",
    "\n",
    "**Note:** In this example we apply the same transformation pipeline to both subsets. However, the pipeline could be different for each subset if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set length: 672\n",
      "Test set length: 168\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset in train and test subsets\n",
    "train_set, test_set = random_split(dataset, [0.8, 0.2], [train_pipeline, test_pipeline])\n",
    "\n",
    "# Print the length of the subsets\n",
    "print(f\"Train set length: {len(train_set)}\")\n",
    "print(f\"Test set length: {len(test_set)}\")\n",
    "\n",
    "# Create a DataLoader\n",
    "train_loader = DataLoader(train_set, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(test_set, batch_size=2, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can start the training we also need to define the model, the loss function and the optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model and optimizer\n",
    "model = DefectClassifier3DCNN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the training loop with the following code. The training loop is very simple and only consists of a few lines of code. For real world applications you might want to add more features like logging, early stopping, learning rate scheduling, etc.\n",
    "\n",
    "**Note:** The training loop is stopped after 30 batches and only runs 1 epoch for demonstration purposes! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Training:\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 285696]' is invalid for input of size 36864",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/sagemaker-user/pyThermoNDT/examples/example4_model_training.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://axhvrvjfjtfg192.studio.eu-central-1.sagemaker.aws/home/sagemaker-user/pyThermoNDT/examples/example4_model_training.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell://axhvrvjfjtfg192.studio.eu-central-1.sagemaker.aws/home/sagemaker-user/pyThermoNDT/examples/example4_model_training.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://axhvrvjfjtfg192.studio.eu-central-1.sagemaker.aws/home/sagemaker-user/pyThermoNDT/examples/example4_model_training.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m output \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     <a href='vscode-notebook-cell://axhvrvjfjtfg192.studio.eu-central-1.sagemaker.aws/home/sagemaker-user/pyThermoNDT/examples/example4_model_training.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Compute the loss\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://axhvrvjfjtfg192.studio.eu-central-1.sagemaker.aws/home/sagemaker-user/pyThermoNDT/examples/example4_model_training.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(output, label)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/pyThermoNDT/examples/example_models/defect_classifier.py:54\u001b[0m, in \u001b[0;36mDefectClassifier3DCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     50\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool4(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv4(x)))\n\u001b[1;32m     51\u001b[0m \u001b[39m# print(\"After fourth conv layer: \", x.shape)\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \n\u001b[1;32m     53\u001b[0m \u001b[39m# Flatten the tensor for the fully connected layer\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m128\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39m6\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39m6\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39m62\u001b[39;49m)  \u001b[39m# Flattening the 3D output to 1D\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39m# print(\"After flattening: \", x.shape)\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \n\u001b[1;32m     57\u001b[0m \u001b[39m# Pass through fully connected layers\u001b[39;00m\n\u001b[1;32m     58\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(x))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 285696]' is invalid for input of size 36864"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    print(\"Training:\")\n",
    "    for batch_idx, (data, label) in enumerate(train_loader):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = loss_fn(output, label)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print the loss\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Batch {batch_idx}, Loss: {loss.item()}\")\n",
    "        \n",
    "        # Stop after 30 batches\n",
    "        if batch_idx == 30:\n",
    "            break\n",
    "\n",
    "    # Evaluate the model\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_loss_summed = 0\n",
    "        print(\"Validation:\")\n",
    "        for batch_idx, (data, label) in enumerate(val_loader):\n",
    "            # Forward pass\n",
    "            output = model(data)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = loss_fn(output, label)\n",
    "            val_loss_summed += loss.item()\n",
    "\n",
    "            # Stop after 30 batches\n",
    "            if batch_idx == 30:\n",
    "                break\n",
    "        \n",
    "        \n",
    "        print(f\"Validation Loss: {val_loss_summed / len(val_loader)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythermondt-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
